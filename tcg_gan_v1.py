# -*- coding: utf-8 -*-
"""TCG GAN V1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K0_uUlOtgZnQKUU90rwYIohgf9Lqm-GS
"""

import torch
torch.manual_seed(42)
import numpy as np
import matplotlib.pyplot as plt

from tqdm.notebook import tqdm

"""**Configurations**"""

device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(device)
batch_size = 128 #trainloader.training loop
noise_dim = 64 #generator model

#optimizer parameters
lr =0.0001
beta_1 = 0.5
beta_2 = 0.99

#training variables
epochs = 400

"""**Import kaggle dataset**"""

!pip install kagglehub
import kagglehub

# Download latest version
path = kagglehub.dataset_download("stefanneacsu/dm-01-06")

print("Path to dataset files:", path)

"""**Move the dataset to content folder**"""

import shutil
shutil.move(path,"/content")

from torchvision import datasets, transforms as T

train_augs = T.Compose([
    T.Resize((128,128)), #redimensionez imaginea pentru o antrenare mai rapida si mai usoara
    T.ToTensor(), #(h,w,c) -> (c,h,w)
])

import os
import shutil

source_dir = '/content/8/cards' # This path now correctly points to the copied data
dest_dir = os.path.join(source_dir, 'all_images')

# Create the destination directory if it doesn't exist
os.makedirs(dest_dir, exist_ok=True)

# Move all .jpg files from source_dir to dest_dir
for filename in os.listdir(source_dir):
    if filename.endswith('.jpg'):
        shutil.move(os.path.join(source_dir, filename), os.path.join(dest_dir, filename))

trainset = datasets.ImageFolder('/content/8/cards', transform = train_augs) # This will now work

import matplotlib.pyplot as plt
image, label =trainset[5]
plt.imshow(image.permute(1, 2, 0))

print("total images in train set are:",len(trainset))

"""**Load Dataset Into Batches**"""

from torch.utils.data import DataLoader
from torchvision.utils import make_grid

trainloader = DataLoader(trainset, batch_size = batch_size, shuffle =True)

print("total mo of batches in trainloader:",len(trainloader))

dataiter = iter(trainloader)
images, _ = next(dataiter)
print(images.shape)

# 'show_tensor_images' : function is used to plot some of images from the batch

def show_tensor_images(tensor_img, num_images = 4, size=(3, 128, 128)):
    unflat_img = tensor_img.detach().cpu()
    # Normalizează din [-1, 1] în [0, 1]
    unflat_img = (unflat_img + 1) / 2
    # Clipping pentru siguranță
    unflat_img = torch.clamp(unflat_img, 0, 1)
    img_grid = make_grid(unflat_img[:num_images], nrow=4)
    plt.imshow(img_grid.permute(1, 2, 0).squeeze())
    plt.show()

show_tensor_images(images, num_images =16)

"""**Create Discriminator Network**"""

#In case if torch summary is not installed

!pip install torchsummary

from torch import nn
from torchsummary import summary

def get_disc_block(in_channels, out_channels,kernel_size,stride):
  return nn.Sequential(
      nn.Conv2d(in_channels, out_channels, kernel_size, stride),
      nn.BatchNorm2d(out_channels),
      nn.LeakyReLU(0.2)
  )
#

class Discriminator(nn.Module):
  def __init__(self):
    super(Discriminator, self).__init__()

    self.block1 = get_disc_block(3, 16, (3,3), 2)
    self.block2 = get_disc_block(16, 32, (5,5), 2)
    self.block3 = get_disc_block(32, 64, (5,5) ,2)

    self.flatten= nn.Flatten()
    # Corrected in_features from 64 to 10816 based on the output shape of block3 (64 * 13 * 13)
    self.linear = nn.Linear(in_features = 10816, out_features =1)
  def forward(self,images):
    x1 = self.block1(images)
    x2 = self.block2(x1)
    x3 = self.block3(x2)

    x4 = self.flatten(x3)
    x5 = self.linear(x4)

    return x5

D = Discriminator()
D.to(device)
summary(D, input_size=(3,128,128))

"""**Create Generator Network**"""

def get_gen_block(in_channels, out_channels, kernel_size, stride, padding=0, output_padding=0, final_block =False):
  if final_block == True:
   return nn.Sequential(
      nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding=padding, output_padding=output_padding),
      nn.Tanh()
  )
  return nn.Sequential(
      nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding=padding, output_padding=output_padding),
      nn.BatchNorm2d(out_channels),
      nn.ReLU()
   )

class Generator(nn.Module):
  def __init__(self, noise_dim):
    super(Generator, self).__init__()
    self.noise_dim = noise_dim

    # Project noise_dim to 512x4x4 spatial representation
    self.initial_projection = nn.Sequential(
        nn.Linear(noise_dim, 512 * 4 * 4),
        nn.ReLU(True)
    )

    # Upsampling blocks to go from 4x4 to 128x128
    self.conv_blocks = nn.Sequential(
        # Input: 512x4x4 -> Output: 256x8x8
        get_gen_block(512, 256, kernel_size=4, stride=2, padding=1),
        # Input: 256x8x8 -> Output: 128x16x16
        get_gen_block(256, 128, kernel_size=4, stride=2, padding=1),
        # Input: 128x16x16 -> Output: 64x32x32
        get_gen_block(128, 64, kernel_size=4, stride=2, padding=1),
        # Input: 64x32x32 -> Output: 32x64x64
        get_gen_block(64, 32, kernel_size=4, stride=2, padding=1),
        # Input: 32x64x64 -> Output: 3x128x128 (final_block=True for Tanh and 3 channels)
        get_gen_block(32, 3, kernel_size=4, stride=2, padding=1, final_block=True)
    )

  def forward(self, r_noise_vec):
    # r_noise_vec is (batch_size, noise_dim)
    x = self.initial_projection(r_noise_vec)
    # Reshape to (batch_size, channels, height, width)
    x = x.view(-1, 512, 4, 4)
    x = self.conv_blocks(x)
    return x

G = Generator(noise_dim)
G.to(device)
summary(G, input_size=(1,noise_dim))

# Replace Random initialized weights to Normal weights

def weights_init(m):
    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):
        nn.init.normal_(m.weight, 0.0, 0.02)
    if isinstance(m, nn.BatchNorm2d):
        nn.init.normal_(m.weight, 0.0, 0.02)
        nn.init.constant_(m.bias, 0)

D=D.apply(weights_init)
G=G.apply(weights_init)

"""**Create Loss Function and Load Optimizer**"""

def real_loss(disc_pred):
  criterion = nn.BCEWithLogitsLoss()
  ground_truth = torch.ones_like(disc_pred)
  loss = criterion(disc_pred, ground_truth)
  return loss
def fake_loss(disc_pred):
  criterion = nn.BCEWithLogitsLoss()
  ground_truth = torch.zeros_like(disc_pred)
  loss = criterion(disc_pred, ground_truth)
  return loss

D_opt= torch.optim.Adam(D.parameters(), lr = lr, betas = (beta_1, beta_2))
G_opt= torch.optim.Adam(G.parameters(), lr = lr, betas = (beta_1, beta_2))

"""**Training Loop**"""

# @title
criterion = nn.BCEWithLogitsLoss()

for i in range(epochs):
  total_d_loss = 0.0
  total_g_loss = 0.0
  for real_images, _ in tqdm(trainloader):
    real_images = real_images.to(device)

    # Find loss and update weights for D
    D_opt.zero_grad()

    # Discriminator's prediction on fake images
    noise = torch.randn(batch_size, noise_dim, device = device)
    fake_images = G(noise)
    D_fake_pred = D(fake_images.detach()) # Detach to prevent G from updating from D's loss
    D_fake_loss = fake_loss(D_fake_pred)

    # Discriminator's prediction on real images
    D_real_pred = D(real_images)
    D_real_loss = real_loss(D_real_pred)

    # Total discriminator loss
    D_loss = (D_real_loss + D_fake_loss) / 2

    total_d_loss += D_loss.item()

    D_loss.backward()
    D_opt.step()

    # Find loss and update weights for G
    G_opt.zero_grad()

    noise = torch.randn(batch_size, noise_dim, device = device)
    fake_images = G(noise)
    D_pred_for_G = D(fake_images)
    G_loss = real_loss(D_pred_for_G) # Generator wants D to classify fake images as real

    total_g_loss += G_loss.item()

    G_loss.backward()
    G_opt.step()

  avg_d_loss = total_d_loss/len(trainloader)
  avg_g_loss = total_g_loss/len(trainloader)


  print("Epoch {}: | D_loss: {:.4f} | G_loss: {:.4f}".format(i+1, avg_d_loss, avg_g_loss))
  show_tensor_images(fake_images)